{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlVNdxaOMYbT"
      },
      "outputs": [],
      "source": [
        "#import the dataset\n",
        "from google.colab import files\n",
        "uploads=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "#load the dataset\n",
        "df=pd.read_csv('all_tickets_processed_improved_v3.csv')\n",
        "\n",
        "print(\"Dataset shape: \",df.shape)\n",
        "\n",
        "print(\"\\nDataset columns: \")\n",
        "print(df.columns.to_list())\n",
        "\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDatatypes:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "R_U93kPcMspY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"SUPPORT TICKET DATASET - OVERVIEW\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nDataset size: {len(df):,} tickets\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TICKET CATEGORIES\")\n",
        "print(\"=\"*70)\n",
        "print(df['Topic_group'].value_counts())\n",
        "print(f\"\\nTotal categories: {df['Topic_group'].nunique()}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['Topic_group'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Support Ticket Category Distribution')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Number of Tickets')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sample tickets per category\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE TICKETS BY CATEGORY\")\n",
        "print(\"=\"*70)\n",
        "for category in df['Topic_group'].unique()[:3]:\n",
        "    print(f\"\\n{category}:\")\n",
        "    sample = df[df['Topic_group'] == category]['Document'].iloc[0]\n",
        "    print(f\"  {sample[:150]}...\")"
      ],
      "metadata": {
        "id": "_zJVGNYBIw6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 2: TEXT CLEANING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "df['text_clean'] = df['Document'].apply(clean_text)\n",
        "\n",
        "# Show before/after\n",
        "print(\"\\nSample 1 (Hardware):\")\n",
        "print(f\"BEFORE: {df[df['Topic_group']=='Hardware']['Document'].iloc[0][:150]}...\")\n",
        "print(f\"AFTER:  {df[df['Topic_group']=='Hardware']['text_clean'].iloc[0][:150]}...\")\n",
        "\n",
        "print(\"\\nSample 2 (HR Support):\")\n",
        "print(f\"BEFORE: {df[df['Topic_group']=='HR Support']['Document'].iloc[0][:150]}...\")\n",
        "print(f\"AFTER:  {df[df['Topic_group']=='HR Support']['text_clean'].iloc[0][:150]}...\")\n",
        "\n",
        "print(f\"\\n‚úì {len(df):,} tickets cleaned\")"
      ],
      "metadata": {
        "id": "H5p1kHcZQyFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 3: TF-IDF FEATURE EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare features and target\n",
        "X = df['text_clean']\n",
        "y = df['Topic_group']\n",
        "\n",
        "# Train/test split (80/20) - stratified\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nData split:\")\n",
        "print(f\"  Training: {len(X_train):,} tickets\")\n",
        "print(f\"  Testing:  {len(X_test):,} tickets\")\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    min_df=5,\n",
        "    max_df=0.8,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "print(\"\\nVectorizing...\")\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\n‚úì Feature extraction complete:\")\n",
        "print(f\"  Vocabulary: {len(vectorizer.vocabulary_):,} features\")\n",
        "print(f\"  Training matrix: {X_train_tfidf.shape}\")\n",
        "print(f\"  Testing matrix: {X_test_tfidf.shape}\")\n",
        "\n",
        "# Sample features\n",
        "features = vectorizer.get_feature_names_out()\n",
        "print(f\"\\nSample features: {list(features[:20])}\")"
      ],
      "metadata": {
        "id": "DmofC4O-RGVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 4: MODEL TRAINING - TICKET CATEGORY CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "models = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    # Accuracy\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'predictions': y_pred,\n",
        "        'accuracy': acc\n",
        "    }\n",
        "\n",
        "    print(f\"  ‚úì Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "# Best model\n",
        "best_name = max(results, key=lambda x: results[x]['accuracy'])\n",
        "best_model = results[best_name]['model']\n",
        "best_pred = results[best_name]['predictions']\n",
        "best_acc = results[best_name]['accuracy']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"üèÜ BEST MODEL: {best_name}\")\n",
        "print(f\"   Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "aH3wF6nRRVN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 5: MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Classification Report (Precision, Recall, F1-Score)\n",
        "print(\"\\nCLASSIFICATION REPORT:\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, best_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "cm = confusion_matrix(y_test, best_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=best_model.classes_,\n",
        "            yticklabels=best_model.classes_,\n",
        "            cbar_kws={'label': 'Number of Tickets'})\n",
        "plt.title(f'Confusion Matrix - {best_name}\\nOverall Accuracy: {best_acc*100:.2f}%',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Actual Category', fontsize=12)\n",
        "plt.xlabel('Predicted Category', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Class-wise performance analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASS-WISE PERFORMANCE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1, support = precision_recall_fscore_support(\n",
        "    y_test, best_pred, labels=best_model.classes_\n",
        ")\n",
        "\n",
        "performance_df = pd.DataFrame({\n",
        "    'Category': best_model.classes_,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1-Score': f1,\n",
        "    'Support': support\n",
        "}).sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(performance_df.to_string(index=False))\n",
        "\n",
        "# Visualize class-wise F1 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(performance_df['Category'], performance_df['F1-Score'], color='green', alpha=0.7)\n",
        "plt.xlabel('F1-Score', fontsize=12)\n",
        "plt.ylabel('Category', fontsize=12)\n",
        "plt.title('F1-Score by Category', fontsize=14, fontweight='bold')\n",
        "plt.xlim(0, 1)\n",
        "for i, (cat, score) in enumerate(zip(performance_df['Category'], performance_df['F1-Score'])):\n",
        "    plt.text(score + 0.01, i, f'{score:.3f}', va='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Step 5 Complete: Model fully evaluated\")"
      ],
      "metadata": {
        "id": "CzA3s4DZR_SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SAVING MODEL FOR DEPLOYMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save the trained model (best_model from Step 4)\n",
        "joblib.dump(best_model, 'ticket_classifier_model.pkl')\n",
        "print(\"‚úì Model saved: ticket_classifier_model.pkl\")\n",
        "\n",
        "# Save the vectorizer (from Step 3)\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "print(\"‚úì Vectorizer saved: tfidf_vectorizer.pkl\")\n",
        "\n",
        "# Save category labels\n",
        "categories = list(best_model.classes_)\n",
        "joblib.dump(categories, 'categories.pkl')\n",
        "print(\"‚úì Categories saved: categories.pkl\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FILES CREATED - DOWNLOAD THEM NOW\")\n",
        "print(\"=\"*70)\n",
        "print(\"1. ticket_classifier_model.pkl\")\n",
        "print(\"2. tfidf_vectorizer.pkl\")\n",
        "print(\"3. categories.pkl\")"
      ],
      "metadata": {
        "id": "TMRV_pqDcM1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all 3 files\n",
        "from google.colab import files\n",
        "\n",
        "files.download('ticket_classifier_model.pkl')\n",
        "files.download('tfidf_vectorizer.pkl')\n",
        "files.download('categories.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Jbun1E5idvAR",
        "outputId": "a9938ec3-24ac-418a-aaad-8523c0b37073"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1b872e39-c1c9-4472-b746-f1131a208ea6\", \"ticket_classifier_model.pkl\", 321159)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b7f74e0-505c-4831-ba19-4a04fd30035c\", \"tfidf_vectorizer.pkl\", 201776)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dc59d6b2-0a6c-4cef-88e1-dde62ec694ec\", \"categories.pkl\", 129)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}